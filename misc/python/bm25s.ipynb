{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da1d71ea27ac4cfa8057b79db899cd07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Split strings:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abf967852a50433b87e398119fa444cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stem Tokens:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b114731b03fd4126a7eed17d8a86d571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BM25S Count Tokens:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb14d0f18c814098a9f9a03c41f3cfe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BM25S Compute Scores:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76a33777bdb54f6ba20590adc8a90918",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Split strings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f45b46b0267d4dbd9d98e8faca04c0ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stem Tokens:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "229dde82fcc645b6a52653b812776b33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BM25S Retrieve:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1 (score: 1.59): a cat is a feline and likes to purr\n",
      "Rank 2 (score: 0.48): a fish is a creature that lives in water and swims\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16d5d0e2030d4379b409670393ad948d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding newlines for mmindex:   0%|          | 0.00/256 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import bm25s\n",
    "import Stemmer  # optional: for stemming\n",
    "\n",
    "# Create your corpus here\n",
    "corpus = [\n",
    "    \"a cat is a feline and likes to purr\",\n",
    "    \"a dog is the human's best friend and loves to play\",\n",
    "    \"a bird is a beautiful animal that can fly\",\n",
    "    \"a fish is a creature that lives in water and swims\",\n",
    "]\n",
    "\n",
    "# optional: create a stemmer\n",
    "stemmer = Stemmer.Stemmer(\"english\")\n",
    "\n",
    "# Tokenize the corpus and only keep the ids (faster and saves memory)\n",
    "corpus_tokens = bm25s.tokenize(corpus, stopwords=\"en\", stemmer=stemmer)\n",
    "\n",
    "# Create the BM25 model and index the corpus\n",
    "retriever = bm25s.BM25()\n",
    "retriever.index(corpus_tokens)\n",
    "\n",
    "# Query the corpus\n",
    "query = \"does the fish purr like a cat?\"\n",
    "query_tokens = bm25s.tokenize(query, stemmer=stemmer)\n",
    "\n",
    "# Get top-k results as a tuple of (doc ids, scores). Both are arrays of shape (n_queries, k)\n",
    "results, scores = retriever.retrieve(query_tokens, corpus=corpus, k=2)\n",
    "\n",
    "for i in range(results.shape[1]):\n",
    "    doc, score = results[0, i], scores[0, i]\n",
    "    print(f\"Rank {i+1} (score: {score:.2f}): {doc}\")\n",
    "\n",
    "# You can save the arrays to a directory...\n",
    "retriever.save(\"animal_index_bm25\")\n",
    "\n",
    "# You can save the corpus along with the model\n",
    "retriever.save(\"animal_index_bm25\", corpus=corpus)\n",
    "\n",
    "# ...and load them when you need them\n",
    "import bm25s\n",
    "reloaded_retriever = bm25s.BM25.load(\"animal_index_bm25\", load_corpus=True)\n",
    "# set load_corpus=False if you don't need the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eee2d0a61fb4644a55dc9a92e8a937c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Split strings:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fc6d297176543dba2fce80b32bc837a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stem Tokens:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8932c48c54d74ce8985ce90325e8dc2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Split strings:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8068d011802a48a7ad4328b63b57c6fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reconstructing token strings:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d4ced734af44604b6f25f4715b0d3c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BM25S Retrieve:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1: About Cat\n",
      "Rank 2: About Dog\n"
     ]
    }
   ],
   "source": [
    "# You can provide a list of queries instead of a single query\n",
    "queries = [\"What is a cat?\", \"is the bird a dog?\"]\n",
    "\n",
    "# Provide your own stopwords list if you don't like the default one\n",
    "stopwords = [\"a\", \"the\"]\n",
    "\n",
    "# For stemming, use any function that is callable on each word list\n",
    "stemmer_fn = lambda lst: [word for word in lst]\n",
    "\n",
    "# Tokenize the queries\n",
    "query_token_ids = bm25s.tokenize(queries, stopwords=stopwords, stemmer=stemmer_fn)\n",
    "\n",
    "# If you want the tokenizer to return strings instead of token ids, you can do this\n",
    "query_token_strs = bm25s.tokenize(queries, return_ids=False)\n",
    "\n",
    "# You can use a different corpus for retrieval, e.g., titles instead of full docs\n",
    "titles = [\"About Cat\", \"About Dog\", \"About Bird\", \"About Fish\"]\n",
    "\n",
    "# You can also choose to only return the documents and omit the scores\n",
    "results = retriever.retrieve(query_token_ids, corpus=titles, k=2, return_as=\"documents\")\n",
    "\n",
    "# The documents are returned as a numpy array of shape (n_queries, k)\n",
    "for i in range(results.shape[1]):\n",
    "    print(f\"Rank {i+1}: {results[0, i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a BM25 index\n",
    "# ...\n",
    "\n",
    "# let's say you have a large corpus\n",
    "corpus = [\n",
    "    \"a very long document that is very long and has many words\",\n",
    "    \"another long document that is long and has many words\",\n",
    "    # ...\n",
    "]\n",
    "# Save the BM25 index to a file\n",
    "retriever.save(\"bm25s_very_big_index\", corpus=corpus)\n",
    "\n",
    "# Load the BM25 index as a memory-mapped file, which is memory efficient\n",
    "# and reduce overhead of loading the full index into memory\n",
    "retriever = bm25s.BM25.load(\"bm25s_very_big_index\", mmap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "176cdb8c395942c1b96f9e9ac24202aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Split strings:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83b50f3fdec04cdc8ef4a2129f335073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BM25S Count Tokens:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "958b1d8371204301aad493bf3a121ed0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BM25S Compute Scores:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1e1f8af9d0f41c6aeb1275f7eeae0d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Split strings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aac64baee9e4d73a0f1a09744cfa254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BM25S Retrieve:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1 (score: 1.06): {'text': 'a cat is a feline and likes to purr', 'metadata': {'source': 'internet'}}\n",
      "Rank 2 (score: 0.48): {'text': 'a fish is a creature that lives in waiter and swims', 'metadata': {'source': 'i made it up'}}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4275e1cc6f3c4b1c872a2d5db1d2fa00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding newlines for mmindex:   0%|          | 0.00/364 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Sometimes, you might want to have a corpus consisting of dict rather than pure text.\n",
    "\n",
    "dicts, and any json-serializable object, is supported by bm25s. This example shows you how to pass a list of dict.\n",
    "\n",
    "Note: If the elements in your corpus is not json serializable, it will not be properly saved. In those cases, you \n",
    "should avoid passing \n",
    "\"\"\"\n",
    "import bm25s\n",
    "\n",
    "# Create your corpus here\n",
    "\n",
    "corpus_json = [\n",
    "    {\"text\": \"a cat is a feline and likes to purr\", \"metadata\": {\"source\": \"internet\"}},\n",
    "    {\"text\": \"a dog is the human's best friend and loves to play\", \"metadata\": {\"source\": \"encyclopedia\"}},\n",
    "    {\"text\": \"a bird is a beautiful animal that can fly\", \"metadata\": {\"source\": \"cnn\"}},\n",
    "    {\"text\": \"a fish is a creature that lives in waiter and swims\", \"metadata\": {\"source\": \"i made it up\"}},\n",
    "]\n",
    "corpus_text = [doc[\"text\"] for doc in corpus_json]\n",
    "\n",
    "\n",
    "# Tokenize the corpus and only keep the ids (faster and saves memory)\n",
    "corpus_tokens = bm25s.tokenize(corpus_text, stopwords=\"en\")\n",
    "\n",
    "# Create the BM25 retriever and attach your corpus_json to it\n",
    "retriever = bm25s.BM25(corpus=corpus_json)\n",
    "# Now, index the corpus_tokens (the corpus_json is not used yet)\n",
    "retriever.index(corpus_tokens)\n",
    "\n",
    "# Query the corpus\n",
    "query = \"does the fish purr like a cat?\"\n",
    "query_tokens = bm25s.tokenize(query)\n",
    "\n",
    "# Get top-k results as a tuple of (doc, scores). Note that results\n",
    "# will correspond to the corpus item at the corresponding index\n",
    "# (you are responsible to make sure each element in corpus_json\n",
    "# corresponds to each element in your tokenized corpus)\n",
    "results, scores = retriever.retrieve(query_tokens, k=2)\n",
    "\n",
    "for i in range(results.shape[1]):\n",
    "    doc, score = results[0, i], scores[0, i]\n",
    "    print(f\"Rank {i+1} (score: {score:.2f}): {doc}\")\n",
    "\n",
    "# You can save the arrays to a directory...\n",
    "# Note that this will fail if your corpus passed to `BM25(corpus...)` is not serializable\n",
    "retriever.save(\"animal_index_bm25\")\n",
    "\n",
    "# ...and load them when you need them\n",
    "import bm25s\n",
    "reloaded_retriever = bm25s.BM25.load(\"animal_index_bm25\", load_corpus=True)\n",
    "# set load_corpus=False if you don't need the corp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'beir'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 18\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m# Example: Indexing Natural Questions\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m```\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbeir\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbeir\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GenericDataLoader\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mStemmer\u001b[39;00m  \u001b[38;5;66;03m# from PyStemmer\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'beir'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Example: Indexing Natural Questions\n",
    "\n",
    "This shows how to build an index of the natural questions dataset using BM25S.\n",
    "\n",
    "To run this example, you need to install the following dependencies:\n",
    "\n",
    "```bash\n",
    "pip install beir bm25s PyStemmer\n",
    "```\n",
    "\n",
    "Then, run with:\n",
    "\n",
    "```bash\n",
    "python examples/index_nq.py\n",
    "```\n",
    "\"\"\"\n",
    "import beir.util\n",
    "from beir.datasets.data_loader import GenericDataLoader\n",
    "import Stemmer  # from PyStemmer\n",
    "\n",
    "import bm25s\n",
    "from bm25s.utils.beir import BASE_URL\n",
    "\n",
    "\n",
    "def main(save_dir=\"datasets\", index_dir=\"bm25s_indices/nq\", dataset=\"nq\"):\n",
    "    data_path = beir.util.download_and_unzip(BASE_URL.format(dataset), save_dir)\n",
    "    corpus, _, __ = GenericDataLoader(data_folder=data_path).load(split=\"test\")\n",
    "    corpus_records = [\n",
    "        {'id': k, 'title': v[\"title\"], 'text': v[\"text\"]} for k, v in corpus.items()\n",
    "    ]\n",
    "    corpus_lst = [r[\"title\"] + \" \" + r[\"text\"] for r in corpus_records]\n",
    "\n",
    "    stemmer = Stemmer.Stemmer(\"english\")\n",
    "    corpus_tokenized = bm25s.tokenize(corpus_lst, stemmer=stemmer)\n",
    "\n",
    "    retriever = bm25s.BM25(corpus=corpus_records)\n",
    "    retriever.index(corpus_tokenized)\n",
    "    retriever.save(index_dir)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
